{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install textblob\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\zjw64\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import time\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication\n",
    "def get_authen():\n",
    "    apiKey = \"mi3IsHw1lzA9KlstGoEi4sQSu\"\n",
    "    apiSecret = \"0obn2WECJqrZt5eoYJoOY5HbHCQfa5Xe6PFW58EG3AEqF4dxUM\"\n",
    "    accessToken = \"1441571989357957122-eksbtpbuyFyQiMnIm9t3DOkILvzXLV\"\n",
    "    accessTokenSecret = \"aLssavUn0tPln5czeoWaVcf0UYSRYAoenbyBIdf7TPvBE\"\n",
    "    auth = tweepy.OAuthHandler(apiKey, apiSecret)\n",
    "    auth.set_access_token(accessToken, accessTokenSecret)\n",
    "    # api = tweepy.API(auth)\n",
    "    api =tweepy.API(auth)\n",
    "    return api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get input\n",
    "def get_keyword():\n",
    "    keyword = input(\"Please enter keyword to search: \")\n",
    "    return keyword\n",
    "\n",
    "def get_numOfTweet():\n",
    "    numOfTweet = input (\"Please enter the number of tweets to analyze: \")\n",
    "    return numOfTweet\n",
    "\n",
    "def test_numOfTweet(numOfTweet):\n",
    "    # number of input tweets should be an integer from 0 to 2000\n",
    "    if numOfTweet.isdigit() and int(numOfTweet) <= 2000 and int(numOfTweet) >= 0:\n",
    "        return numOfTweet\n",
    "    else: \n",
    "        return \"input_num_wrong\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search tweets\n",
    "def get_twi_list(keyword, numOfTweet):\n",
    "    api = get_authen()\n",
    "    tweets = tweepy.Cursor(api.search_tweets, q=keyword).items(int(numOfTweet))\n",
    "    tweet_list = []\n",
    "    for tweet in tweets:\n",
    "        tweet_list.append(tweet.text)\n",
    "\n",
    "    tweet_list = pd.DataFrame(tweet_list)\n",
    "    # delete duplicates\n",
    "    tweet_list.drop_duplicates(inplace = True)\n",
    "\n",
    "    return tweet_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment analyze\n",
    "def sentiment_analyze(tweet_list):\n",
    "    #Extracting text values\n",
    "    tw_list = pd.DataFrame(tweet_list)\n",
    "    if tw_list.empty:\n",
    "        return tw_list\n",
    "    tw_list[\"text\"] = tw_list[0]\n",
    "\n",
    "    #Cleaning Text (RT, Punctuation etc)\n",
    "    tw_list = pd.DataFrame(tweet_list)\n",
    "    tw_list[\"text\"] = tw_list[0]\n",
    "    remove_rt = lambda x: re.sub('RT @\\w+: ',\" \",x)\n",
    "    rt = lambda x: re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",x)\n",
    "    tw_list[\"text\"] = tw_list.text.map(remove_rt).map(rt)\n",
    "    tw_list[\"text\"] = tw_list.text.str.lower()\n",
    "\n",
    "    if tw_list.empty:\n",
    "        return tw_list\n",
    "\n",
    "    #Calculating Negative, Positive, Neutral and Compound values\n",
    "    tw_list[['polarity', 'subjectivity']] = tw_list['text'].apply(lambda Text: pd.Series(TextBlob(Text).sentiment))\n",
    "    for index, row in tw_list['text'].iteritems():\n",
    "        score = SentimentIntensityAnalyzer().polarity_scores(row)\n",
    "        neg = score['neg']\n",
    "        neu = score['neu']\n",
    "        pos = score['pos']\n",
    "        comp = score['compound']\n",
    "        if neg > pos:\n",
    "            tw_list.loc[index, 'sentiment'] = \"negative\"\n",
    "        elif pos > neg:\n",
    "            tw_list.loc[index, 'sentiment'] = \"positive\"\n",
    "        else:\n",
    "            tw_list.loc[index, 'sentiment'] = \"neutral\"\n",
    "        tw_list.loc[index, 'neg'] = neg\n",
    "        tw_list.loc[index, 'neu'] = neu\n",
    "        tw_list.loc[index, 'pos'] = pos\n",
    "        tw_list.loc[index, 'compound'] = comp\n",
    "\n",
    "    #Creating new data frames for all sentiments (positive, negative and neutral)\n",
    "    tw_list_negative = tw_list[tw_list[\"sentiment\"]==\"negative\"]\n",
    "    tw_list_positive = tw_list[tw_list[\"sentiment\"]==\"positive\"]\n",
    "    tw_list_neutral = tw_list[tw_list[\"sentiment\"]==\"neutral\"]\n",
    "\n",
    "    return tw_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_values_in_column(data):\n",
    "    #Function for count_values_in single columns\n",
    "    feature = \"sentiment\"\n",
    "    total=data.loc[:,feature].value_counts(dropna=False)\n",
    "    percentage=round(data.loc[:,feature].value_counts(dropna=False,normalize=True)*100,2)\n",
    "    return pd.concat([total,percentage],axis=1,keys=['Total','Percentage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_limit_alert(time_diff, search_num):\n",
    "    # stop searching when search 15 times in 15 minutes\n",
    "    if time_diff/60 < 15 and search_num >= 15:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "Please enter keyword to search: wechat status\n",
      "Please enter the number of tweets to analyze: 500\n",
      "Tweet total number:  187\n",
      "\n",
      "-------------------------------------\n",
      "Sentiment Analysis: (10 samples)\n",
      "                                                    0  \\\n",
      "0   RT @jakaena1: Also a guy commented on one of h...   \n",
      "1   WITHDRAW RM2000🎉\\nJOIN NOW!!\\nWelcome Bonus 30...   \n",
      "2   RT @NaNcRaZy: กำลังนั่งอ่าน wechat ของ China H...   \n",
      "4   برائے فروخت ۔ خریدنے کیلئے فالو کرو ۔ اور انبا...   \n",
      "6   برائے فروخت ۔ خریدنے کیلئے فالو کرو ۔ اور انبا...   \n",
      "9   Chinese man said some hurty words about traffi...   \n",
      "10  RT @Buce2021: I suggest that if you have #FEG,...   \n",
      "13  RT @Chikaofficials: GSC 1/8 สเกลฟิกเกอร์ #ปรมา...   \n",
      "14  یاد اپ WeChat بخیر، فحش مینوشتیم میذاشتیم داخل...   \n",
      "15  RT @WYB85_MeMories: 191030 #왕이보 #WangYibo\\n▪Or...   \n",
      "16  RT @bocheeeez: 公式がWeChatのフリート的な機能でマップ豆知識みたいなやつ...   \n",
      "\n",
      "                                                 text  polarity  subjectivity  \\\n",
      "0    also a guy commented on one of her douyin s p...       0.1          0.40   \n",
      "1   withdraw rm2000  join now   welcome bonus 30  ...       0.8          0.90   \n",
      "2                  wechat     china hip hop union ...       0.0          0.00   \n",
      "4                                                 ...       0.0          0.00   \n",
      "6                                                 ...       0.0          0.00   \n",
      "9   chinese man said some hurty words about traffi...       0.1          0.25   \n",
      "10   i suggest that if you have  feg  please chang...       0.5          0.50   \n",
      "13   gsc 1 8                                 ver  ...       0.0          0.00   \n",
      "14         wechat                                 ...       0.0          0.00   \n",
      "15   191030       wangyibo  origins     wechat upd...       0.0          0.00   \n",
      "16      wechat                                    ...       0.0          0.00   \n",
      "\n",
      "   sentiment    neg    neu    pos  compound  \n",
      "0    neutral  0.000  1.000  0.000    0.0000  \n",
      "1   positive  0.000  0.580  0.420    0.8271  \n",
      "2   negative  0.182  0.818  0.000   -0.2500  \n",
      "4    neutral  0.000  1.000  0.000    0.0000  \n",
      "6    neutral  0.000  1.000  0.000    0.0000  \n",
      "9   positive  0.000  0.889  0.111    0.3612  \n",
      "10  positive  0.000  0.785  0.215    0.6697  \n",
      "13   neutral  0.000  1.000  0.000    0.0000  \n",
      "14   neutral  0.000  1.000  0.000    0.0000  \n",
      "15   neutral  0.000  1.000  0.000    0.0000  \n",
      "16   neutral  0.000  1.000  0.000    0.0000  \n",
      "\n",
      "-------------------------------------\n",
      "Count Value for Sentiment Analysis: \n",
      "          Total  Percentage\n",
      "neutral      99       52.94\n",
      "positive     71       37.97\n",
      "negative     17        9.09\n",
      "\n",
      "-------------------------------------\n",
      "Please enter keyword to search: cnasijducnpaos;udn\n",
      "Please enter the number of tweets to analyze: 10\n",
      "Tweet total number:  0\n",
      "\n",
      "-------------------------------------\n",
      "Sentiment Analysis: (10 samples)\n",
      "WARNING: 0 tweet found.\n",
      "-------------------------------------\n",
      "Please enter keyword to search: red sox\n",
      "Please enter the number of tweets to analyze: 100000\n",
      "Please enter an integer from 0 to 2000.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Instantiate an object\n",
    "    start_time = time.time()\n",
    "    search_num = 0\n",
    "\n",
    "    while True:\n",
    "        end_time = time.time()\n",
    "        if search_limit_alert((end_time-start_time), search_num):\n",
    "            print(\"-------------------------------------\")\n",
    "            print(\"You have no chance to search in 15 minites.\")\n",
    "            print()\n",
    "            break\n",
    "\n",
    "        print(\"-------------------------------------\")\n",
    "        keyword = get_keyword()\n",
    "\n",
    "        while True:\n",
    "            numOfTweet = get_numOfTweet()\n",
    "            test = test_numOfTweet(numOfTweet)\n",
    "            if test == \"input_num_wrong\":\n",
    "                print(\"Please enter an integer from 0 to 2000.\")\n",
    "            else:\n",
    "                break   \n",
    "\n",
    "        tweet_list = get_twi_list(keyword, numOfTweet)\n",
    "        print(\"Tweet total number: \",len(tweet_list))\n",
    "        print()\n",
    "\n",
    "        print(\"-------------------------------------\")\n",
    "        tw_list = sentiment_analyze(tweet_list)\n",
    "        search_num = search_num + 1\n",
    "        print(\"Sentiment Analysis: (10 samples)\")\n",
    "        if tw_list.empty:\n",
    "            print(\"WARNING: 0 tweet found.\")\n",
    "        else:\n",
    "            print(tw_list.head(11))\n",
    "            print()\n",
    "            print(\"-------------------------------------\")\n",
    "            print(\"Count Value for Sentiment Analysis: \")\n",
    "            print(count_values_in_column(tw_list))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
