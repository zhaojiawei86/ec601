{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install textblob\n",
    "# !pip install tweepy\n",
    "# !pip install google.cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from google.cloud import language\n",
    "from google.cloud import language_v1\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "# nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication\n",
    "apiKey = \"mi3IsHw1lzA9KlstGoEi4sQSu\"\n",
    "apiSecret = \"0obn2WECJqrZt5eoYJoOY5HbHCQfa5Xe6PFW58EG3AEqF4dxUM\"\n",
    "accessToken = \"1441571989357957122-eksbtpbuyFyQiMnIm9t3DOkILvzXLV\" \n",
    "accessTokenSecret = \"aLssavUn0tPln5czeoWaVcf0UYSRYAoenbyBIdf7TPvBE\"\n",
    "auth = tweepy.OAuthHandler(apiKey, apiSecret)\n",
    "auth.set_access_token(accessToken, accessTokenSecret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiates a client\n",
    "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/path/to/file.json\"\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"C:/Users/zjw64/Desktop/ec601/project2/service-account-file.json\"\n",
    "client = language_v1.LanguageServiceClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search tweets\n",
    "keyword = input(\"Please enter keyword to search: \")\n",
    "numOfTweet = int(input (\"Please enter the number of tweets to analyze: \"))\n",
    "\n",
    "tweets = tweepy.Cursor(api.search_tweets, q=keyword).items(numOfTweet)\n",
    "tweet_list = []\n",
    "for tweet in tweets:\n",
    "    tweet_list.append(tweet.text)\n",
    "\n",
    "tweet_list = pd.DataFrame(tweet_list)\n",
    "print(\"search number: \",len(tweet_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete duplicates\n",
    "tweet_list.drop_duplicates(inplace = True)\n",
    "print(\"total number: \",len(tweet_list))\n",
    "\n",
    "#Extracting text values\n",
    "tw_list = pd.DataFrame(tweet_list)\n",
    "tw_list[\"text\"] = tw_list[0]\n",
    "print(tw_list.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Text (RT, Punctuation etc)\n",
    "\n",
    "#Creating new dataframe and new features\n",
    "tw_list = pd.DataFrame(tweet_list)\n",
    "tw_list[\"text\"] = tw_list[0]\n",
    "\n",
    "#Removing RT, Punctuation etc\n",
    "remove_rt = lambda x: re.sub('RT @\\w+: ',\" \",x)\n",
    "rt = lambda x: re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",x)\n",
    "tw_list[\"text\"] = tw_list.text.map(remove_rt).map(rt)\n",
    "tw_list[\"text\"] = tw_list.text.str.lower()\n",
    "print(tw_list.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Twitter sentiment analyze\n",
    "tw_twi = tw_list.copy(deep=True)\n",
    "tw_twi[['polarity', 'subjectivity']] = tw_twi['text'].apply(lambda Text: pd.Series(TextBlob(Text).sentiment))\n",
    "for index, row in tw_twi['text'].iteritems():\n",
    "    score = SentimentIntensityAnalyzer().polarity_scores(row)\n",
    "    neg = score['neg']\n",
    "    neu = score['neu']\n",
    "    pos = score['pos']\n",
    "    comp = score['compound']\n",
    "    if neg > pos:\n",
    "        tw_twi.loc[index, 'sentiment'] = \"negative\"\n",
    "    elif pos > neg:\n",
    "        tw_twi.loc[index, 'sentiment'] = \"positive\"\n",
    "    else:\n",
    "        tw_twi.loc[index, 'sentiment'] = \"neutral\"\n",
    "    tw_twi.loc[index, 'neg'] = neg\n",
    "    tw_twi.loc[index, 'neu'] = neu\n",
    "    tw_twi.loc[index, 'pos'] = pos\n",
    "    tw_twi.loc[index, 'compound'] = comp\n",
    "\n",
    "print(tw_twi.head(10))\n",
    "\n",
    "#Creating new data frames for all sentiments (positive, negative and neutral)\n",
    "tw_twi_negative = tw_twi[tw_twi[\"sentiment\"]==\"negative\"]\n",
    "tw_twi_positive = tw_twi[tw_twi[\"sentiment\"]==\"positive\"]\n",
    "tw_twi_neutral = tw_twi[tw_twi[\"sentiment\"]==\"neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google NLP API sentiment analyze\n",
    "tw_goo = tw_list.copy(deep=True)\n",
    "for index, tweet in tw_goo['text'].iteritems():\n",
    "    document = language_v1.Document(content=tweet.encode('utf-8'), type_=language_v1.Document.Type.PLAIN_TEXT)\n",
    "    sentiment = client.analyze_sentiment(request={'document': document}).document_sentiment\n",
    "    tw_goo.loc[index, 'score'] = sentiment.score\n",
    "\n",
    "    if sentiment.score >= -1.0 and sentiment.score < -0.25:\n",
    "        tw_goo.loc[index, 'sentiment'] = \"negative\"\n",
    "    elif sentiment.score >= -0.25 and sentiment.score <= 0.25:\n",
    "        tw_goo.loc[index, 'sentiment'] = \"neutral\"\n",
    "    else:\n",
    "        tw_goo.loc[index, 'sentiment'] = \"positive\"\n",
    "\n",
    "print(tw_goo.head(10))\n",
    "\n",
    "\n",
    "#Creating new data frames for all sentiments (positive, negative and neutral)\n",
    "\n",
    "tw_goo_negative = tw_goo[tw_goo[\"sentiment\"]==\"negative\"]\n",
    "tw_goo_positive = tw_goo[tw_goo[\"sentiment\"]==\"positive\"]\n",
    "tw_goo_neutral = tw_goo[tw_goo[\"sentiment\"]==\"neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter API sentiment analyze: \n",
      "          Total  Percentage\n",
      "neutral     273       65.16\n",
      "positive     95       22.67\n",
      "negative     51       12.17\n",
      "Google NLP sentiment analyze: \n",
      "          Total  Percentage\n",
      "NaN         363       86.63\n",
      "neutral      32        7.64\n",
      "positive     15        3.58\n",
      "negative      9        2.15\n"
     ]
    }
   ],
   "source": [
    "#Function for count_values_in single columns\n",
    "\n",
    "def count_values_in_column(data,feature):\n",
    "    total=data.loc[:,feature].value_counts(dropna=False)\n",
    "    percentage=round(data.loc[:,feature].value_counts(dropna=False,normalize=True)*100,2)\n",
    "    return pd.concat([total,percentage],axis=1,keys=['Total','Percentage'])\n",
    "\n",
    "#Count_values for sentiment\n",
    "print(\"Twitter API sentiment analyze: \")\n",
    "print(count_values_in_column(tw_twi,\"sentiment\"))\n",
    "print(\"Google NLP sentiment analyze: \")\n",
    "print(count_values_in_column(tw_goo,\"sentiment\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
