{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install textblob\n",
    "!pip install tweepy\n",
    "!pip install google.cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\zjw64\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "from google.cloud import language\n",
    "from google.cloud import language_v1\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication\n",
    "apiKey = \"mi3IsHw1lzA9KlstGoEi4sQSu\"\n",
    "apiSecret = \"0obn2WECJqrZt5eoYJoOY5HbHCQfa5Xe6PFW58EG3AEqF4dxUM\"\n",
    "accessToken = \"1441571989357957122-eksbtpbuyFyQiMnIm9t3DOkILvzXLV\" \n",
    "accessTokenSecret = \"aLssavUn0tPln5czeoWaVcf0UYSRYAoenbyBIdf7TPvBE\"\n",
    "auth = tweepy.OAuthHandler(apiKey, apiSecret)\n",
    "auth.set_access_token(accessToken, accessTokenSecret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiates a client\n",
    "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/path/to/file.json\"\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"C:/Users/zjw64/Desktop/ec601/project2/service-account-file.json\"\n",
    "client = language_v1.LanguageServiceClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter keyword to search: red sox\n",
      "Please enter the number of tweets to analyze: 500\n",
      "search number:  500\n"
     ]
    }
   ],
   "source": [
    "#search tweets\n",
    "keyword = input(\"Please enter keyword to search: \")\n",
    "numOfTweet = int(input (\"Please enter the number of tweets to analyze: \"))\n",
    "\n",
    "tweets = tweepy.Cursor(api.search_tweets, q=keyword).items(numOfTweet)\n",
    "tweet_list = []\n",
    "for tweet in tweets:\n",
    "    tweet_list.append(tweet.text)\n",
    "\n",
    "tweet_list = pd.DataFrame(tweet_list)\n",
    "print(\"search number: \",len(tweet_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number:  157\n",
      "                                                    0  \\\n",
      "0   @AlexandraLeslie @wpri12 Very sad day in Red S...   \n",
      "1   RT @NHLBruins: The Boston Bruins mourn the los...   \n",
      "2   RT @Eck43: Red Sox nation has lost a beloved i...   \n",
      "3   RT @19fredlynn: I lost a great teammate and fr...   \n",
      "4   RT @BGlobeSports: .@GlobeChadFinn: There were ...   \n",
      "5   RT @joonlee: RIP Jerry Remy, forever a Red Sox...   \n",
      "7   Jerry Remy, a Boston Red Sox second baseman wh...   \n",
      "8   RT @RedSox: This weekend we lost our beloved J...   \n",
      "10  RT @RedSox: A truly great player, broadcaster,...   \n",
      "11  RT @BGlobeSports: Jerry Remy, an undersized ev...   \n",
      "\n",
      "                                                 text  \n",
      "0   @AlexandraLeslie @wpri12 Very sad day in Red S...  \n",
      "1   RT @NHLBruins: The Boston Bruins mourn the los...  \n",
      "2   RT @Eck43: Red Sox nation has lost a beloved i...  \n",
      "3   RT @19fredlynn: I lost a great teammate and fr...  \n",
      "4   RT @BGlobeSports: .@GlobeChadFinn: There were ...  \n",
      "5   RT @joonlee: RIP Jerry Remy, forever a Red Sox...  \n",
      "7   Jerry Remy, a Boston Red Sox second baseman wh...  \n",
      "8   RT @RedSox: This weekend we lost our beloved J...  \n",
      "10  RT @RedSox: A truly great player, broadcaster,...  \n",
      "11  RT @BGlobeSports: Jerry Remy, an undersized ev...  \n"
     ]
    }
   ],
   "source": [
    "# delete duplicates\n",
    "tweet_list.drop_duplicates(inplace = True)\n",
    "print(\"total number: \",len(tweet_list))\n",
    "\n",
    "#Extracting text values\n",
    "tw_list = pd.DataFrame(tweet_list)\n",
    "tw_list[\"text\"] = tw_list[0]\n",
    "print(tw_list.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    0  \\\n",
      "0   @AlexandraLeslie @wpri12 Very sad day in Red S...   \n",
      "1   RT @NHLBruins: The Boston Bruins mourn the los...   \n",
      "2   RT @Eck43: Red Sox nation has lost a beloved i...   \n",
      "3   RT @19fredlynn: I lost a great teammate and fr...   \n",
      "4   RT @BGlobeSports: .@GlobeChadFinn: There were ...   \n",
      "5   RT @joonlee: RIP Jerry Remy, forever a Red Sox...   \n",
      "7   Jerry Remy, a Boston Red Sox second baseman wh...   \n",
      "8   RT @RedSox: This weekend we lost our beloved J...   \n",
      "10  RT @RedSox: A truly great player, broadcaster,...   \n",
      "11  RT @BGlobeSports: Jerry Remy, an undersized ev...   \n",
      "\n",
      "                                                 text  \n",
      "0                  very sad day in red sox nation      \n",
      "1    the boston bruins mourn the loss of jerry rem...  \n",
      "2    red sox nation has lost a beloved icon   i lo...  \n",
      "3    i lost a great teammate and friend today  a t...  \n",
      "4        there were so many reasons for red sox fa...  \n",
      "5    rip jerry remy  forever a red sox legend in t...  \n",
      "7   jerry remy  a boston red sox second baseman wh...  \n",
      "8    this weekend we lost our beloved jerry remy  ...  \n",
      "10   a truly great player  broadcaster  and friend...  \n",
      "11   jerry remy  an undersized everyman of a ballp...  \n"
     ]
    }
   ],
   "source": [
    "#Cleaning Text (RT, Punctuation etc)\n",
    "\n",
    "#Creating new dataframe and new features\n",
    "tw_list = pd.DataFrame(tweet_list)\n",
    "tw_list[\"text\"] = tw_list[0]\n",
    "\n",
    "#Removing RT, Punctuation etc\n",
    "remove_rt = lambda x: re.sub('RT @\\w+: ',\" \",x)\n",
    "rt = lambda x: re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",x)\n",
    "tw_list[\"text\"] = tw_list.text.map(remove_rt).map(rt)\n",
    "tw_list[\"text\"] = tw_list.text.str.lower()\n",
    "print(tw_list.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    0  \\\n",
      "0   @AlexandraLeslie @wpri12 Very sad day in Red S...   \n",
      "1   RT @NHLBruins: The Boston Bruins mourn the los...   \n",
      "2   RT @Eck43: Red Sox nation has lost a beloved i...   \n",
      "3   RT @19fredlynn: I lost a great teammate and fr...   \n",
      "4   RT @BGlobeSports: .@GlobeChadFinn: There were ...   \n",
      "5   RT @joonlee: RIP Jerry Remy, forever a Red Sox...   \n",
      "7   Jerry Remy, a Boston Red Sox second baseman wh...   \n",
      "8   RT @RedSox: This weekend we lost our beloved J...   \n",
      "10  RT @RedSox: A truly great player, broadcaster,...   \n",
      "11  RT @BGlobeSports: Jerry Remy, an undersized ev...   \n",
      "\n",
      "                                                 text  score sentiment  \n",
      "0                  very sad day in red sox nation       -0.7  negative  \n",
      "1    the boston bruins mourn the loss of jerry rem...    0.0   neutral  \n",
      "2    red sox nation has lost a beloved icon   i lo...   -0.1   neutral  \n",
      "3    i lost a great teammate and friend today  a t...   -0.6  negative  \n",
      "4        there were so many reasons for red sox fa...    0.3  positive  \n",
      "5    rip jerry remy  forever a red sox legend in t...    0.3  positive  \n",
      "7   jerry remy  a boston red sox second baseman wh...    0.1   neutral  \n",
      "8    this weekend we lost our beloved jerry remy  ...   -0.6  negative  \n",
      "10   a truly great player  broadcaster  and friend...    0.8  positive  \n",
      "11   jerry remy  an undersized everyman of a ballp...   -0.4  negative  \n"
     ]
    }
   ],
   "source": [
    "# Google NLP API sentiment analyze\n",
    "tw_goo = tw_list.copy(deep=True)\n",
    "for index, tweet in tw_goo['text'].iteritems():\n",
    "    document = language_v1.Document(content=tweet.encode('utf-8'), type_=language_v1.Document.Type.PLAIN_TEXT)\n",
    "    sentiment = client.analyze_sentiment(request={'document': document}).document_sentiment\n",
    "    tw_goo.loc[index, 'score'] = sentiment.score\n",
    "\n",
    "    if sentiment.score >= -1.0 and sentiment.score < -0.25:\n",
    "        tw_goo.loc[index, 'sentiment'] = \"negative\"\n",
    "    elif sentiment.score >= -0.25 and sentiment.score <= 0.25:\n",
    "        tw_goo.loc[index, 'sentiment'] = \"neutral\"\n",
    "    else:\n",
    "        tw_goo.loc[index, 'sentiment'] = \"positive\"\n",
    "\n",
    "print(tw_goo.head(10))\n",
    "\n",
    "\n",
    "#Creating new data frames for all sentiments (positive, negative and neutral)\n",
    "\n",
    "tw_goo_negative = tw_goo[tw_goo[\"sentiment\"]==\"negative\"]\n",
    "tw_goo_positive = tw_goo[tw_goo[\"sentiment\"]==\"positive\"]\n",
    "tw_goo_neutral = tw_goo[tw_goo[\"sentiment\"]==\"neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google NLP sentiment analyze: \n",
      "          Total  Percentage\n",
      "neutral      61       38.85\n",
      "negative     51       32.48\n",
      "positive     45       28.66\n"
     ]
    }
   ],
   "source": [
    "#Function for count_values_in single columns\n",
    "\n",
    "def count_values_in_column(data,feature):\n",
    "    total=data.loc[:,feature].value_counts(dropna=False)\n",
    "    percentage=round(data.loc[:,feature].value_counts(dropna=False,normalize=True)*100,2)\n",
    "    return pd.concat([total,percentage],axis=1,keys=['Total','Percentage'])\n",
    "\n",
    "#Count_values for sentiment\n",
    "print(\"Google NLP sentiment analyze: \")\n",
    "print(count_values_in_column(tw_goo,\"sentiment\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
